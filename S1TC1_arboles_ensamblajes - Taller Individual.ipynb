{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de árboles de decisión y métodos de ensamblaje\n",
    "\n",
    "En este taller podrá poner en práctica los sus conocimientos sobre construcción e implementación de árboles de decisión y métodos de ensamblajes. El taller está constituido por 9 puntos, 5 relacionados con árboles de decisión (parte A) y 4 con métodos de ensamblaje (parte B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte A - Árboles de decisión\n",
    "\n",
    "En esta parte del taller se usará el conjunto de datos de Capital Bikeshare de Kaggle, donde cada observación representa el alquiler de bicicletas durante una hora y día determinado. Para más detalles puede visitar los siguientes enlaces: [datos](https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip), [dicccionario de datos](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos prestamo de bicicletas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>total</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season  holiday  workingday  weather  temp   atemp  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "                     humidity  windspeed  casual  registered  total  hour  \n",
       "datetime                                                                   \n",
       "2011-01-01 00:00:00        81        0.0       3          13     16     0  \n",
       "2011-01-01 01:00:00        80        0.0       8          32     40     1  \n",
       "2011-01-01 02:00:00        80        0.0       5          27     32     2  \n",
       "2011-01-01 03:00:00        75        0.0       3          10     13     3  \n",
       "2011-01-01 04:00:00        75        0.0       0           1      1     4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "bikes = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/bikeshare.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# Renombrar variable \"count\" a \"total\"\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Crear la hora como una variable \n",
    "bikes['hour'] = bikes.index.hour\n",
    "\n",
    "# Visualización de los datos\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Análisis descriptivo\n",
    "\n",
    "Ejecute las celdas 1.1 y 1.2. A partir de los resultados realice un análisis descriptivo sobre las variables \"season\" y \"hour\", escriba sus inferencias sobre los datos. Para complementar su análisis puede usar métricas como máximo, mínimo, percentiles entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "1    116.343261\n",
       "2    215.251372\n",
       "3    234.417124\n",
       "4    198.988296\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.1\n",
    "bikes.groupby('season').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0      55.138462\n",
       "1      33.859031\n",
       "2      22.899554\n",
       "3      11.757506\n",
       "4       6.407240\n",
       "5      19.767699\n",
       "6      76.259341\n",
       "7     213.116484\n",
       "8     362.769231\n",
       "9     221.780220\n",
       "10    175.092308\n",
       "11    210.674725\n",
       "12    256.508772\n",
       "13    257.787281\n",
       "14    243.442982\n",
       "15    254.298246\n",
       "16    316.372807\n",
       "17    468.765351\n",
       "18    430.859649\n",
       "19    315.278509\n",
       "20    228.517544\n",
       "21    173.370614\n",
       "22    133.576754\n",
       "23     89.508772\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 1.2\n",
    "bikes.groupby('hour').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.0</td>\n",
       "      <td>55.138462</td>\n",
       "      <td>43.620012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>74.50</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454.0</td>\n",
       "      <td>33.859031</td>\n",
       "      <td>34.112105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448.0</td>\n",
       "      <td>22.899554</td>\n",
       "      <td>26.110267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433.0</td>\n",
       "      <td>11.757506</td>\n",
       "      <td>12.666442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442.0</td>\n",
       "      <td>6.407240</td>\n",
       "      <td>4.217633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>452.0</td>\n",
       "      <td>19.767699</td>\n",
       "      <td>12.784293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>455.0</td>\n",
       "      <td>76.259341</td>\n",
       "      <td>54.745333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>75.0</td>\n",
       "      <td>118.00</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>455.0</td>\n",
       "      <td>213.116484</td>\n",
       "      <td>159.207044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>208.0</td>\n",
       "      <td>334.00</td>\n",
       "      <td>596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>455.0</td>\n",
       "      <td>362.769231</td>\n",
       "      <td>231.723065</td>\n",
       "      <td>8.0</td>\n",
       "      <td>133.50</td>\n",
       "      <td>392.0</td>\n",
       "      <td>563.50</td>\n",
       "      <td>839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>455.0</td>\n",
       "      <td>221.780220</td>\n",
       "      <td>92.099209</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>294.50</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>455.0</td>\n",
       "      <td>175.092308</td>\n",
       "      <td>101.807629</td>\n",
       "      <td>17.0</td>\n",
       "      <td>106.00</td>\n",
       "      <td>149.0</td>\n",
       "      <td>218.50</td>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>455.0</td>\n",
       "      <td>210.674725</td>\n",
       "      <td>127.444294</td>\n",
       "      <td>10.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>183.0</td>\n",
       "      <td>265.50</td>\n",
       "      <td>647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>456.0</td>\n",
       "      <td>256.508772</td>\n",
       "      <td>143.881880</td>\n",
       "      <td>3.0</td>\n",
       "      <td>157.00</td>\n",
       "      <td>234.5</td>\n",
       "      <td>332.00</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>456.0</td>\n",
       "      <td>257.787281</td>\n",
       "      <td>149.167185</td>\n",
       "      <td>11.0</td>\n",
       "      <td>154.00</td>\n",
       "      <td>226.5</td>\n",
       "      <td>329.00</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>456.0</td>\n",
       "      <td>243.442982</td>\n",
       "      <td>147.563199</td>\n",
       "      <td>12.0</td>\n",
       "      <td>144.00</td>\n",
       "      <td>212.0</td>\n",
       "      <td>311.25</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>456.0</td>\n",
       "      <td>254.298246</td>\n",
       "      <td>144.235670</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.00</td>\n",
       "      <td>232.0</td>\n",
       "      <td>331.00</td>\n",
       "      <td>724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>456.0</td>\n",
       "      <td>316.372807</td>\n",
       "      <td>145.664786</td>\n",
       "      <td>11.0</td>\n",
       "      <td>211.75</td>\n",
       "      <td>309.5</td>\n",
       "      <td>421.00</td>\n",
       "      <td>783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>456.0</td>\n",
       "      <td>468.765351</td>\n",
       "      <td>223.775485</td>\n",
       "      <td>15.0</td>\n",
       "      <td>277.00</td>\n",
       "      <td>480.5</td>\n",
       "      <td>608.50</td>\n",
       "      <td>970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456.0</td>\n",
       "      <td>430.859649</td>\n",
       "      <td>219.908138</td>\n",
       "      <td>23.0</td>\n",
       "      <td>240.75</td>\n",
       "      <td>422.5</td>\n",
       "      <td>564.00</td>\n",
       "      <td>977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>456.0</td>\n",
       "      <td>315.278509</td>\n",
       "      <td>156.641732</td>\n",
       "      <td>11.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>312.5</td>\n",
       "      <td>416.00</td>\n",
       "      <td>743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>456.0</td>\n",
       "      <td>228.517544</td>\n",
       "      <td>116.411565</td>\n",
       "      <td>11.0</td>\n",
       "      <td>136.75</td>\n",
       "      <td>224.0</td>\n",
       "      <td>302.00</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>456.0</td>\n",
       "      <td>173.370614</td>\n",
       "      <td>87.629319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>103.50</td>\n",
       "      <td>171.5</td>\n",
       "      <td>230.00</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>456.0</td>\n",
       "      <td>133.576754</td>\n",
       "      <td>69.844495</td>\n",
       "      <td>9.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>129.0</td>\n",
       "      <td>175.00</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>456.0</td>\n",
       "      <td>89.508772</td>\n",
       "      <td>51.638004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count        mean         std   min     25%    50%     75%    max\n",
       "hour                                                                   \n",
       "0     455.0   55.138462   43.620012   2.0   24.00   41.0   74.50  283.0\n",
       "1     454.0   33.859031   34.112105   1.0   11.00   19.0   46.00  168.0\n",
       "2     448.0   22.899554   26.110267   1.0    5.00   11.0   32.00  119.0\n",
       "3     433.0   11.757506   12.666442   1.0    3.00    6.0   15.00   66.0\n",
       "4     442.0    6.407240    4.217633   1.0    3.00    6.0    9.00   28.0\n",
       "5     452.0   19.767699   12.784293   1.0    8.00   19.0   29.00   57.0\n",
       "6     455.0   76.259341   54.745333   1.0   24.50   75.0  118.00  213.0\n",
       "7     455.0  213.116484  159.207044   1.0   63.00  208.0  334.00  596.0\n",
       "8     455.0  362.769231  231.723065   8.0  133.50  392.0  563.50  839.0\n",
       "9     455.0  221.780220   92.099209  14.0  161.00  217.0  294.50  414.0\n",
       "10    455.0  175.092308  101.807629  17.0  106.00  149.0  218.50  539.0\n",
       "11    455.0  210.674725  127.444294  10.0  123.00  183.0  265.50  647.0\n",
       "12    456.0  256.508772  143.881880   3.0  157.00  234.5  332.00  757.0\n",
       "13    456.0  257.787281  149.167185  11.0  154.00  226.5  329.00  729.0\n",
       "14    456.0  243.442982  147.563199  12.0  144.00  212.0  311.25  730.0\n",
       "15    456.0  254.298246  144.235670   7.0  154.00  232.0  331.00  724.0\n",
       "16    456.0  316.372807  145.664786  11.0  211.75  309.5  421.00  783.0\n",
       "17    456.0  468.765351  223.775485  15.0  277.00  480.5  608.50  970.0\n",
       "18    456.0  430.859649  219.908138  23.0  240.75  422.5  564.00  977.0\n",
       "19    456.0  315.278509  156.641732  11.0  190.00  312.5  416.00  743.0\n",
       "20    456.0  228.517544  116.411565  11.0  136.75  224.0  302.00  551.0\n",
       "21    456.0  173.370614   87.629319   6.0  103.50  171.5  230.00  584.0\n",
       "22    456.0  133.576754   69.844495   9.0   80.00  129.0  175.00  502.0\n",
       "23    456.0   89.508772   51.638004   4.0   52.75   80.0  123.00  256.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.groupby('hour').total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2686.0</td>\n",
       "      <td>116.343261</td>\n",
       "      <td>125.273974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2733.0</td>\n",
       "      <td>215.251372</td>\n",
       "      <td>192.007843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2733.0</td>\n",
       "      <td>234.417124</td>\n",
       "      <td>197.151001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2734.0</td>\n",
       "      <td>198.988296</td>\n",
       "      <td>177.622409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>948.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std  min   25%    50%    75%    max\n",
       "season                                                                \n",
       "1       2686.0  116.343261  125.273974  1.0  24.0   78.0  164.0  801.0\n",
       "2       2733.0  215.251372  192.007843  1.0  49.0  172.0  321.0  873.0\n",
       "3       2733.0  234.417124  197.151001  1.0  68.0  195.0  347.0  977.0\n",
       "4       2734.0  198.988296  177.622409  1.0  51.0  161.0  294.0  948.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.groupby('season').total.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis descriptivo\n",
    "\n",
    "Como se puede ver en las celdas anteriores, el invierno es la época del año en la que menos se rentan bicicletas en promedio, mientras que el verano es la época en la que más se rentan. Adicionalmente, las 5/6 de la tarde es la hora en la que más se rentan bicicletas, mientras que las 4 de la mañana es la hora en la que menos se rentan en promedio. El momento con más bicicletas rentadas han sido los veranos a las 6 de la tarde, con un acumulado de 977. En la base de datos no hay momentos en los que no se haya rentado ninguna bicicleta, pero el mínimo ha sido una."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Análisis de gráficos\n",
    "\n",
    "Primero ejecute la celda 2.1 y asegúrese de comprender el código y el resultado. Luego, en cada una de celdas 2.2 y 2.3 escriba un código que genere una gráfica del número de bicicletas rentadas promedio para cada valor de la variable \"hour\" (hora) cuando la variable \"season\" es igual a 1 (invierno) e igual a 3 (verano), respectivamente. Analice y escriba sus hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x75dcf18402d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.1 - rentas promedio para cada valor de la variable \"hour\"\n",
    "bikes.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x75dcef6e9910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.2 - \"season\"=1 escriba su código y hallazgos \n",
    "winter = bikes[bikes['season'] == 1]\n",
    "winter.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x75dcef6768d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2.3 - \"season\"=3 escriba su código y hallazgos \n",
    "summer = bikes[bikes['season'] == 3]\n",
    "summer.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallazgos\n",
    "\n",
    "Como se puede ver en las gráficas, el comportamiento promedio de los usuarios que rentan bicicletas no cambia cuando cambian las estaciones ni es lineal. Tanto en invierno, como en verano, como en todo el año, los usuarios prefieren rentar bicicletas a las 5-6 de la tarde, mientras que evitan rentarlas a las 4 de la mañana. Esto implica que el momento del día en el que se renta una bicicleta no depende de la estación. Es decir, estas variables parecen ser independientes entre sí (no hay multicolinealidad). Sin embargo, si se ve puede ver que la estación si influye en la cantidad de bicicletas que se rentan, pues en invierno se rentan menos bicicletas en promedio. Finalmente, en general, la renta de bicicletas aumenta y disminuye a lo largo del día, lo que implica que no hay linealidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Regresión lineal\n",
    "En la celda 3 ajuste un modelo de regresión lineal a todo el conjunto de datos, utilizando \"total\" como variable de respuesta y \"season\" y \"hour\" como las únicas variables predictoras, teniendo en cuenta que la variable \"season\" es categórica. Luego, imprima los coeficientes e interprételos. ¿Cuáles son las limitaciones de la regresión lineal en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepto: -6.430262462305961\n",
      "Coeficientes de hour y season: [ 10.54520609 100.31723192 119.46754995  84.08311787]\n",
      "Error cuadrático medio (MSE): 25386.08153987355\n",
      "Coeficiente de determinación (R^2): 0.230886452360323\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "# Separación de variables predictoras (X) y variable de interes (y)\n",
    "bikes_encoded = pd.get_dummies(bikes, columns=['season'])\n",
    "X = bikes_encoded[['hour','season_2', 'season_3', 'season_4']]\n",
    "y = bikes_encoded['total']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Calcular las predicciones en el conjunto de validación\n",
    "y_pred = model.predict(X_val)\n",
    "# Calcular métricas de desempeño del modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Imprimir los coeficientes\n",
    "print(\"Intercepto:\", model.intercept_)\n",
    "print(\"Coeficientes de hour y season:\", model.coef_)\n",
    "\n",
    "# Imprimir métricas de desempeño del modelo\n",
    "print(\"Error cuadrático medio (MSE):\", mse)\n",
    "print(\"Coeficiente de determinación (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación\n",
    "\n",
    "Según los resultados de la regresión lineal, cuando el día aumenta en una hora, se espera que el número de bicicletas rentadas aumente en 10, todo lo demás constante. Adicionalmente, en las temporadas primavera, verano y otoño, la renta de bicicletas aumenta en 100.3, 119.5 y 84.1 en promedio con respecto al invierno.\n",
    "\n",
    "En este caso, las limitaciones de usar este modelo de regresión lineal es que el comportamiento de la hora del día parece no ser lineal, pues la renta de bicicletas aumenta hasta las 6 de la tarde, pero disminuye hasta las 4 de la mañana y luego vuelve a subir hasta las 7-8 de la mañana, para luego volver a bajar hasta las 10 de la mañana y finalmente subir hasta las 6 de la tarde nuevamente. Esto implica que el coeficiente de horas no es el más acertado. Por otro lado, el efecto que tienen las estaciones sobre el número de bicicletas rentadas podría interpretarse de mejor forma en un árbol de decisión, teniendo en cuenta los hallazgos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Árbol de decisión manual\n",
    "En la celda 4 cree un árbol de decisiones para pronosticar la variable \"total\" iterando **manualmente** sobre las variables \"hour\" y  \"season\". El árbol debe tener al menos 6 nodos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bikes[['hour','season']]\n",
    "y = bikes['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour\n"
     ]
    }
   ],
   "source": [
    "# Impresión variable a usar (Hits)\n",
    "j = 0\n",
    "print(X.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4\n",
    "# Definición de parámetros y criterios de parada\n",
    "max_depth = 6\n",
    "num_pct = 4\n",
    "max_features = None\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  6., 12., 18.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División de las variables en num_ctp puntos (parámetro definido anteriormente) para obtener posibles puntos de corte\n",
    "splits = np.percentile(X.iloc[:, 0], np.arange(0, 100, 100.0 / num_pct).tolist())\n",
    "splits = np.unique(splits)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de las observaciones usando el punto de corte en la posición 3 de la lista de splits\n",
    "k=3\n",
    "filter_l = X.iloc[:, j] < splits[k]\n",
    "\n",
    "# División de la variable de respuesta de acuerdo a si la observación cumple o no con la regla binaria\n",
    "# y_l: la observación tiene un valor menor al punto de corte seleccionado\n",
    "# y_r: la observación tiene un valor mayor o igual al punto de corte seleccionado\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función que calcula el gini index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-63846.62163125448"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gini index de las observaciones que tienen un valor menor al punto de corte seleccionado\n",
    "gini_l = gini(y_l)\n",
    "gini_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-103984.50069492537"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gini index de las observaciones que tienen un valor mayor o igual al punto de corte seleccionado\n",
    "gini_r = gini(y_r)\n",
    "gini_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función gini_imputiry para calular la ganancia de una variable predictora j dado el punto de corte k\n",
    "def gini_impurity(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916.4067193765077"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ganancia de la variable 'Hits' en el punto de corte selecionado\n",
    "gini_impurity(X.iloc[:, j], y, splits[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función best_split para calcular cuál es la mejor variable y punto de cortepara hacer la bifurcación del árbol\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8.0, 18268.811823533004)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención de la variable 'j', su punto de corte 'split' y su ganancia 'gain'\n",
    "j, split, gain = best_split(X, y, 5)\n",
    "j, split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de las observaciones usando la mejor variable 'j' y su punto de corte 'split'\n",
    "filter_l = X.iloc[:, j] < split\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 3594, 7292)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0], y_l.shape[0], y_r.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191.57413191254824, 55.437673900946024, 258.6715578716402)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(), y_l.mean(), y_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 191.53903379867745,\n",
       " 'level': 0,\n",
       " 'split': [0, 8.0],\n",
       " 'n_samples': 10886,\n",
       " 'gain': 18268.811823533004,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 55.40711902113459,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 3594,\n",
       "  'gain': 7207.700659959655},\n",
       " 'sr': {'y_pred': 1,\n",
       "  'y_prob': 258.6007677543186,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 7292,\n",
       "  'gain': 7392.920792160614}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicación de la función tree_grow\n",
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=1, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 191.53903379867745,\n",
       " 'level': 0,\n",
       " 'split': [0, 8.0],\n",
       " 'n_samples': 10886,\n",
       " 'gain': 18268.811823533004,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 55.40711902113459,\n",
       "  'level': 1,\n",
       "  'split': [0, 7.0],\n",
       "  'n_samples': 3594,\n",
       "  'gain': 7207.700659959655,\n",
       "  'sl': {'y_pred': 1,\n",
       "   'y_prob': 32.561604584527224,\n",
       "   'level': 2,\n",
       "   'split': [0, 6.0],\n",
       "   'n_samples': 3139,\n",
       "   'gain': 646.8008927589567,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 25.15934475055845,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 2684,\n",
       "    'gain': 382.8088308604629},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 75.92778993435448,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 455,\n",
       "    'gain': 743.095592335012}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 212.18599562363238,\n",
       "   'level': 2,\n",
       "   'split': [1, 2.0],\n",
       "   'n_samples': 455,\n",
       "   'gain': 5197.1071057533845,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 122.27826086956522,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 113,\n",
       "    'gain': 0},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 241.01162790697674,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 342,\n",
       "    'gain': 131.37717588317173}}},\n",
       " 'sr': {'y_pred': 1,\n",
       "  'y_prob': 258.6007677543186,\n",
       "  'level': 1,\n",
       "  'split': [0, 21.0],\n",
       "  'n_samples': 7292,\n",
       "  'gain': 7392.920792160614,\n",
       "  'sl': {'y_pred': 1,\n",
       "   'y_prob': 287.7910901113736,\n",
       "   'level': 2,\n",
       "   'split': [1, 2.0],\n",
       "   'n_samples': 5924,\n",
       "   'gain': 8304.11949599313,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 175.89256756756757,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1478,\n",
       "    'gain': 1134.7125713419155},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 324.8943345323741,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 4446,\n",
       "    'gain': 7126.654106105911}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 131.95985401459853,\n",
       "   'level': 2,\n",
       "   'split': [1, 2.0],\n",
       "   'n_samples': 1368,\n",
       "   'gain': 2478.289069001301,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 70.7703488372093,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 342,\n",
       "    'gain': 668.1166854758721},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 152.17996108949416,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1026,\n",
       "    'gain': 2327.263104696969}}}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = tree_grow(X, y, level=0, min_gain=0.001, max_depth=3, num_pct=10)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_predict para hacer predicciones según las variables 'X' y el árbol 'tree'\n",
    "\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecución de función tree_predict\n",
    "tree_predict(X, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Árbol de decisión con librería\n",
    "En la celda 5 entrene un árbol de decisiones con la **librería sklearn**, usando las variables predictoras \"season\" y \"hour\" y calibre los parámetros que considere conveniente para obtener un mejor desempeño. Recuerde dividir los datos en conjuntos de entrenamiento y validación para esto. Comente el desempeño del modelo con alguna métrica de desempeño de modelos de regresión y compare desempeño con el modelo del punto 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE): 13454.101382166964\n",
      "Coeficiente de determinación (R^2): 0.5923856295785829\n"
     ]
    }
   ],
   "source": [
    "# Celda 5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X = bikes[['hour','season']]\n",
    "y = bikes['total']\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Inicializar y entrenar el modelo de árbol de decisiones\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "# Calcular las predicciones en el conjunto de validación\n",
    "y_pred = tree_reg.predict(X_val)\n",
    "# Calcular métricas de desempeño del modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Imprimir métricas de desempeño del modelo\n",
    "print(\"Error cuadrático medio (MSE):\", mse)\n",
    "print(\"Coeficiente de determinación (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios sobre desempeño\n",
    "Considerando que el MSE del modelo del punto 3 fue 25386 y su R2 fue de 0.23, podemos concluir que el árbol de decisión tiene un desempeño mucho mejor con una mejor bondad de ajuste y un error cuadrático medio menor (MSE = 13454.1, R2=0.59)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B - Métodos de ensamblajes\n",
    "En esta parte del taller se usará el conjunto de datos de Popularidad de Noticias Online. El objetivo es predecir si la notica es popular o no, la popularidad está dada por la cantidad de reacciones en redes sociales. Para más detalles puede visitar el siguiente enlace: [datos](https://archive.ics.uci.edu/ml/datasets/online+news+popularity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos popularidad de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.844262        5.0             1.0       1.0  ...   \n",
       "1                  0.815789        9.0             4.0       1.0  ...   \n",
       "2                  0.775701        4.0             3.0       1.0  ...   \n",
       "3                  0.677350       10.0             3.0       1.0  ...   \n",
       "4                  0.830357        3.0             2.0       1.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/mashable.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición variable de interes y variables predictoras\n",
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de la muestra en set de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - Árbol de decisión y regresión logística\n",
    "En la celda 6 construya un árbol de decisión y una regresión logística. Para el árbol calibre al menos un parámetro y evalúe el desempeño de cada modelo usando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "##Arbol de decision\n",
    "tree_clf = DecisionTreeClassifier(random_state=1)\n",
    "#Calibración\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(tree_clf, n_estimators=10, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)\n",
    "# Entrenemiento del modelo con set de entrenamiento y predicción en el set de test\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "y_pred\n",
    "##Reg logistica\n",
    "# Entrenar la regresión logística\n",
    "log_reg = LogisticRegression(max_iter=10)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de Decisión:\n",
      "Accuracy: 0.618\n",
      "F1-Score: 0.5910064239828694\n",
      "\n",
      "Regresión Logística:\n",
      "Accuracy: 0.5713333333333334\n",
      "F1-Score: 0.5592871830020562\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de desempeño\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy_tree = accuracy_score(y_test, y_pred)\n",
    "f1_tree = f1_score(y_test, y_pred)\n",
    "\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg)\n",
    "\n",
    "print(\"Árbol de Decisión:\")\n",
    "print(\"Accuracy:\", accuracy_tree)\n",
    "print(\"F1-Score:\", f1_tree)\n",
    "\n",
    "print(\"\\nRegresión Logística:\")\n",
    "print(\"Accuracy:\", accuracy_log_reg)\n",
    "print(\"F1-Score:\", f1_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación\n",
    "\n",
    "Como se puede ver, la evaluación de ambos modelos muestran que tienen un desempeño muy similar pues sus valores de Accuracy y F1 son casi iguales. De hecho, la regresión logística es un poco mejor, por lo que aún hay espacio para mejorar el modelo del árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Votación Mayoritaria\n",
    "En la celda 7 elabore un esamble con la metodología de **Votación mayoritaria** compuesto por 300 muestras bagged donde:\n",
    "\n",
    "-las primeras 100 muestras vienen de árboles de decisión donde max_depth tome un valor de su elección\\\n",
    "-las segundas 100 muestras vienen de árboles de decisión donde min_samples_leaf tome un valor de su elección\\\n",
    "-las últimas 100 muestras vienen de regresiones logísticas\n",
    "\n",
    "Evalúe cada uno de los tres modelos de manera independiente utilizando las métricas de Accuracy y F1-Score, luego evalúe el ensamble de modelos y compare los resultados. \n",
    "\n",
    "Nota: \n",
    "\n",
    "Para este ensamble de 300 modelos, deben hacer votación mayoritaria. Esto lo pueden hacer de distintas maneras. La más \"fácil\" es haciendo la votación \"manualmente\", como se hace a partir del minuto 5:45 del video de Ejemplo práctico de emsablajes en Coursera. Digo que es la más fácil porque si hacen la votación mayoritaria sobre las 300 predicciones van a obtener lo que se espera.\n",
    "\n",
    "Otra opción es: para cada uno de los 3 tipos de modelos, entrenar un ensamble de 100 modelos cada uno. Predecir para cada uno de esos tres ensambles y luego predecir como un ensamble de los 3 ensambles. La cuestión es que la votación mayoritaria al usar los 3 ensambles no necesariamente va a generar el mismo resultado que si hacen la votación mayoritaria directamente sobre los 300 modelos. Entonces, para los que quieran hacer esto, deben hacer ese último cálculo con cuidado.\n",
    "\n",
    "Para los que quieran hacerlo como ensamble de ensambles, digo que se debe hacer el ensamble final con cuidado por lo siguiente. Supongamos que:\n",
    "\n",
    "* para los 100 árboles del primer tipo, la votación mayoritaria es: 55% de los modelos predicen que la clase de una observación es \"1\"\n",
    "* para los 100 árboles del segundo tipo, la votación mayoritaria es: 55% de los modelos predicen que la clase de una observación es \"1\"\n",
    "* para las 100 regresiones logísticas, la votación mayoritaria es: 10% de los modelos predicen que la clase de una observación es \"1\"\n",
    "\n",
    "Si se hace la votación mayoritaria de los 300 modelos, la predicción de esa observación debería ser: (100*55%+100*55%+100*10%)/300 = 40% de los modelos votan porque la predicción debería ser \"1\". Es decir, la predicción del ensamble es \"0\" (dado que menos del 50% de modelos predijo un 1).\n",
    "\n",
    "Sin embargo, si miramos cada ensamble por separado, el primer ensamble predice \"1\", el segundo ensamble predice \"1\" y el último ensamble predice \"0\". Si hago votación mayoritaria sobre esto, la predicción va a ser \"1\", lo cual es distinto a si se hace la votación mayoritaria sobre los 300 modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Crear modelos individuales\n",
    "tree_clf1 = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "tree_clf2 = DecisionTreeClassifier(min_samples_leaf=5, random_state=1)\n",
    "log_reg = LogisticRegression(max_iter=10)\n",
    "\n",
    "# Crear ensamble de modelos\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('tree1', BaggingClassifier(tree_clf1, n_estimators=100, random_state=1)),\n",
    "    ('tree2', BaggingClassifier(tree_clf2, n_estimators=100, random_state=1)),\n",
    "    ('log_reg', BaggingClassifier(log_reg, n_estimators=100, random_state=1))\n",
    "], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar modelos individuales\n",
    "tree_clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('tree1',\n",
       "                              BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                                                      class_weight=None,\n",
       "                                                                                      criterion='gini',\n",
       "                                                                                      max_depth=5,\n",
       "                                                                                      max_features=None,\n",
       "                                                                                      max_leaf_nodes=None,\n",
       "                                                                                      min_impurity_decrease=0.0,\n",
       "                                                                                      min_impurity_split=None,\n",
       "                                                                                      min_samples_leaf=1,\n",
       "                                                                                      min_samples_split=2,\n",
       "                                                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                                                      presort='deprecated',\n",
       "                                                                                      random_state=1,\n",
       "                                                                                      spl...\n",
       "                                                                                  max_iter=10,\n",
       "                                                                                  multi_class='auto',\n",
       "                                                                                  n_jobs=None,\n",
       "                                                                                  penalty='l2',\n",
       "                                                                                  random_state=None,\n",
       "                                                                                  solver='lbfgs',\n",
       "                                                                                  tol=0.0001,\n",
       "                                                                                  verbose=0,\n",
       "                                                                                  warm_start=False),\n",
       "                                                bootstrap=True,\n",
       "                                                bootstrap_features=False,\n",
       "                                                max_features=1.0,\n",
       "                                                max_samples=1.0,\n",
       "                                                n_estimators=100, n_jobs=None,\n",
       "                                                oob_score=False, random_state=1,\n",
       "                                                verbose=0, warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar ensamble\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de decisión 1:\n",
      "Accuracy: 0.6373333333333333\n",
      "F1-Score: 0.6616915422885573\n",
      "\n",
      "Árbol de decisión 2:\n",
      "Accuracy: 0.542\n",
      "F1-Score: 0.5459352280237937\n",
      "\n",
      "Regresión Logística:\n",
      "Accuracy: 0.5713333333333334\n",
      "F1-Score: 0.5592871830020562\n",
      "\n",
      "Ensamble:\n",
      "Accuracy: 0.658\n",
      "F1-Score: 0.6559356136820926\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones\n",
    "y_pred_tree1 = tree_clf1.predict(X_test)\n",
    "y_pred_tree2 = tree_clf2.predict(X_test)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_ensemble = ensemble.predict(X_test)\n",
    "\n",
    "# Evaluar modelos individuales\n",
    "accuracy_tree1 = accuracy_score(y_test, y_pred_tree1)\n",
    "f1_tree1 = f1_score(y_test, y_pred_tree1)\n",
    "\n",
    "accuracy_tree2 = accuracy_score(y_test, y_pred_tree2)\n",
    "f1_tree2 = f1_score(y_test, y_pred_tree2)\n",
    "\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg)\n",
    "\n",
    "# Evaluar ensamble\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "f1_ensemble = f1_score(y_test, y_pred_ensemble)\n",
    "\n",
    "# Imprimir métricas de desempeño\n",
    "print(\"Árbol de decisión 1:\")\n",
    "print(\"Accuracy:\", accuracy_tree1)\n",
    "print(\"F1-Score:\", f1_tree1)\n",
    "\n",
    "print(\"\\nÁrbol de decisión 2:\")\n",
    "print(\"Accuracy:\", accuracy_tree2)\n",
    "print(\"F1-Score:\", f1_tree2)\n",
    "\n",
    "print(\"\\nRegresión Logística:\")\n",
    "print(\"Accuracy:\", accuracy_log_reg)\n",
    "print(\"F1-Score:\", f1_log_reg)\n",
    "\n",
    "print(\"\\nEnsamble:\")\n",
    "print(\"Accuracy:\", accuracy_ensemble)\n",
    "print(\"F1-Score:\", f1_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Votación Ponderada\n",
    "En la celda 8 elabore un ensamble con la metodología de **Votación ponderada** compuesto por 300 muestras bagged para los mismos tres escenarios del punto 7. Evalúe los modelos utilizando las métricas de Accuracy y F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamble con votación ponderada:\n",
      "Accuracy: 0.6566666666666666\n",
      "F1-Score: 0.656437625083389\n"
     ]
    }
   ],
   "source": [
    "# Celda 8\n",
    "# Crear modelos individuales\n",
    "tree_clf1 = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "tree_clf2 = DecisionTreeClassifier(min_samples_leaf=5, random_state=1)\n",
    "log_reg = LogisticRegression(max_iter=10)\n",
    "\n",
    "# Crear ensamble de modelos con votación ponderada\n",
    "ensemble_weighted = VotingClassifier(estimators=[\n",
    "    ('tree1', BaggingClassifier(tree_clf1, n_estimators=100, random_state=1, oob_score=True)),\n",
    "    ('tree2', BaggingClassifier(tree_clf2, n_estimators=100, random_state=1, oob_score=True)),\n",
    "    ('log_reg', BaggingClassifier(log_reg, n_estimators=100, random_state=1, oob_score=True))\n",
    "], voting='soft', weights=None)  # Inicialmente sin pesos\n",
    "\n",
    "# Entrenar ensamble para obtener los errores OOB\n",
    "ensemble_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los errores OOB para cada modelo\n",
    "oob_errors = [1 - estimator.oob_score_ for estimator in ensemble_weighted.estimators_]\n",
    "\n",
    "# Calcular los pesos basados en los errores OOB\n",
    "weights = [1 / (1 + error) for error in oob_errors]\n",
    "\n",
    "# Asignar los pesos al ensamble\n",
    "ensemble_weighted.weights = weights\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_ensemble_weighted = ensemble_weighted.predict(X_test)\n",
    "\n",
    "# Evaluar ensamble ponderado\n",
    "accuracy_ensemble_weighted = accuracy_score(y_test, y_pred_ensemble_weighted)\n",
    "f1_ensemble_weighted = f1_score(y_test, y_pred_ensemble_weighted)\n",
    "\n",
    "# Imprimir métricas de desempeño\n",
    "print(\"Ensamble con votación ponderada:\")\n",
    "print(\"Accuracy:\", accuracy_ensemble_weighted)\n",
    "print(\"F1-Score:\", f1_ensemble_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar modelos individuales\n",
    "tree_clf1.fit(X_train, y_train)\n",
    "tree_clf2.fit(X_train, y_train)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de decisión 1:\n",
      "Accuracy: 0.6373333333333333\n",
      "F1-Score: 0.6616915422885573\n",
      "\n",
      "Árbol de decisión 2:\n",
      "Accuracy: 0.542\n",
      "F1-Score: 0.5459352280237937\n",
      "\n",
      "Regresión Logística:\n",
      "Accuracy: 0.5713333333333334\n",
      "F1-Score: 0.5592871830020562\n",
      "\n",
      "Ensamble Ponderado:\n",
      "Accuracy: 0.6566666666666666\n",
      "F1-Score: 0.656437625083389\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones con cada modelo individual\n",
    "y_pred_tree1 = tree_clf1.predict(X_test)\n",
    "y_pred_tree2 = tree_clf2.predict(X_test)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Calcular métricas de rendimiento para cada modelo individual\n",
    "accuracy_tree1 = accuracy_score(y_test, y_pred_tree1)\n",
    "f1_tree1 = f1_score(y_test, y_pred_tree1)\n",
    "\n",
    "accuracy_tree2 = accuracy_score(y_test, y_pred_tree2)\n",
    "f1_tree2 = f1_score(y_test, y_pred_tree2)\n",
    "\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg)\n",
    "\n",
    "# Hacer predicciones con el ensamble ponderado\n",
    "y_pred_ensemble_weighted = ensemble_weighted.predict(X_test)\n",
    "\n",
    "# Calcular métricas de rendimiento para el ensamble ponderado\n",
    "accuracy_ensemble_weighted = accuracy_score(y_test, y_pred_ensemble_weighted)\n",
    "f1_ensemble_weighted = f1_score(y_test, y_pred_ensemble_weighted)\n",
    "\n",
    "# Imprimir métricas de rendimiento para cada modelo individual y el ensamble ponderado\n",
    "print(\"Árbol de decisión 1:\")\n",
    "print(\"Accuracy:\", accuracy_tree1)\n",
    "print(\"F1-Score:\", f1_tree1)\n",
    "print(\"\\nÁrbol de decisión 2:\")\n",
    "print(\"Accuracy:\", accuracy_tree2)\n",
    "print(\"F1-Score:\", f1_tree2)\n",
    "print(\"\\nRegresión Logística:\")\n",
    "print(\"Accuracy:\", accuracy_log_reg)\n",
    "print(\"F1-Score:\", f1_log_reg)\n",
    "print(\"\\nEnsamble Ponderado:\")\n",
    "print(\"Accuracy:\", accuracy_ensemble_weighted)\n",
    "print(\"F1-Score:\", f1_ensemble_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 9 - Comparación y análisis de resultados\n",
    "En la celda 9 comente sobre los resultados obtenidos con las metodologías usadas en los puntos 7 y 8, compare los resultados y enuncie posibles ventajas o desventajas de cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celda 9\n",
    "En ambos casos, el mejor modelo fue el árbol de decisión 2. El ensamble ponderado tuvo un peor desempeño que este modelo en ambos casos. Comparando votación ponderada y mayoritaría, se puede ver que la votación ponderada dio mejores resultados en términos de las métricas F1 y Accuracy, sin embargo la diferencia es mínima. El árbol de decisión del punto 6 tuvo mejores resultados.\n",
    "\n",
    "Con respecto a ventajas y desventajas, la votación ponderada puede ser más flexible y tener un mejor rendimiento en comparación con la votación mayoritaria, especialmente cuando los modelos individuales tienen habilidades predictivas variadas en diferentes regiones del espacio de características. Sin embargo, este modelo tiene riesgo de sobreajuste al requerir más calibración. La votación mayoritaria es más simple y directa de implementar. Se debe tener en cuenta que se usaron pocas iteraciones en la regresión logística debido al requerimiento computacional del ensamblaje (estaba tardando mucho en correr)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
